{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvessong23/ML-TEAM-15/blob/main/BinBuddiesCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDz947BEKBtG"
      },
      "outputs": [],
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJM9MyG1JvjH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "cbf7c354-0599-41bf-aac0-6717305a1c71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.10.5)\n",
            "Using Colab cache for faster access to the 'garbage-dataset-classification' dataset.\n",
            "Path to dataset files: /kaggle/input/garbage-dataset-classification\n",
            "Duplicate found! Removing /kaggle/input/garbage-dataset-classification/Garbage_Dataset_Classification/images/metal/metal_01555.jpg (same as /kaggle/input/garbage-dataset-classification/Garbage_Dataset_Classification/images/metal/metal_00775.jpg)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 30] Read-only file system: '/kaggle/input/garbage-dataset-classification/Garbage_Dataset_Classification/images/metal/metal_01555.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1096707466.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Duplicate found! Removing {file_path} (same as {hashes[h]})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mduplicates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/kaggle/input/garbage-dataset-classification/Garbage_Dataset_Classification/images/metal/metal_01555.jpg'"
          ]
        }
      ],
      "source": [
        "%pip install numpy\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import hashlib, os\n",
        "from PIL import Image\n",
        "%pip install kagglehub\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"zlatan599/garbage-dataset-classification\")\n",
        "rgb_path = \"cleaned/garbage-dataset-rgb\"\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "hashes = {}\n",
        "duplicates = []\n",
        "\n",
        "def file_hash(filePath):\n",
        "    with open(filePath, \"rb\") as f: # Open and read files for hashing\n",
        "        file_bytes = f.read()\n",
        "        return hashlib.md5(file_bytes).hexdigest()\n",
        "\n",
        "for root, dirs, files in os.walk(path):\n",
        "    for file in files:\n",
        "        file_path = os.path.join(root, file)\n",
        "        h = file_hash(file_path)\n",
        "\n",
        "        if h in hashes:\n",
        "            print(f\"Duplicate found! Removing {file_path} (same as {hashes[h]})\")\n",
        "            os.remove(file_path)\n",
        "            duplicates.append((file_path, hashes[h]))\n",
        "        else:\n",
        "            hashes[h] = file_path\n",
        "            try:\n",
        "                # Preserve the dataset’s subfolder structure\n",
        "                rel_dir = os.path.relpath(root, path)\n",
        "                save_dir = os.path.join(rgb_path, rel_dir)\n",
        "                os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "                save_path = os.path.join(save_dir, file)\n",
        "\n",
        "                # Skip non-image files (like metadata.csv)\n",
        "                if not file.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")):\n",
        "                    continue\n",
        "\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.convert(\"RGB\").save(save_path)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2PHRTnEJ9Zf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras import models, layers, regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "rgb_path = \"cleaned/garbage-dataset-rgb\"\n",
        "base_path = os.path.join(rgb_path, \"Garbage_Dataset_Classification\", \"images\")\n",
        "DATASET_DIR = base_path\n",
        "\n",
        "# Set up class names\n",
        "class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Verify and collect all image paths and their labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "for class_idx, class_name in enumerate(class_names):\n",
        "    class_dir = os.path.join(base_path, class_name)\n",
        "    if os.path.exists(class_dir):\n",
        "        class_images = [f for f in os.listdir(class_dir)\n",
        "                       if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
        "        print(f\"{class_name}: {len(class_images)} images\")\n",
        "\n",
        "        for img_file in class_images:\n",
        "            image_paths.append(os.path.join(class_dir, img_file))\n",
        "            labels.append(class_idx)\n",
        "    else:\n",
        "        print(f\"Warning: {class_dir} does not exist\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iVV25H9RXYy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "IMG_HEIGHT = 156\n",
        "IMG_WIDTH = 156\n",
        "IMG_SIZE   = (IMG_HEIGHT, IMG_WIDTH)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.3,\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.3\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATASET_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Load *all* validation images into memory, then split into val + test\n",
        "val_generator_full = val_test_datagen.flow_from_directory(\n",
        "    DATASET_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_data = []\n",
        "val_labels = []\n",
        "\n",
        "for i in range(len(val_generator_full)):\n",
        "    x, y = val_generator_full[i]\n",
        "    val_data.append(x[0])\n",
        "    val_labels.append(y[0])\n",
        "\n",
        "val_data = np.array(val_data)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    val_data,\n",
        "    val_labels,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=np.argmax(val_labels, axis=1)\n",
        ")\n",
        "\n",
        "val_generator_data = (X_val, y_val)\n",
        "test_generator_data = (X_test, y_test)\n",
        "\n",
        "model_gap = models.Sequential([\n",
        "    layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "\n",
        "    # Block 1\n",
        "    layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
        "    layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D(2),\n",
        "\n",
        "    # Block 2\n",
        "    layers.Conv2D(64, (5,5), padding='same', activation='relu'),\n",
        "    layers.Conv2D(64, (5,5), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D(2),\n",
        "\n",
        "    # Block 3\n",
        "    layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
        "    layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D(2),\n",
        "\n",
        "    # Block 4\n",
        "    layers.Conv2D(256, (3,3), padding='same', activation='relu'),\n",
        "    layers.Conv2D(256, (3,3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D(2),\n",
        "\n",
        "    # Head with GAP\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(6, activation='softmax'),\n",
        "])\n",
        "\n",
        "\n",
        "model_flatten = models.Sequential([\n",
        "    layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "\n",
        "    # Block 1\n",
        "    layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
        "    layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D(2),\n",
        "\n",
        "    # Block 2\n",
        "    layers.Conv2D(64, (5,5), padding='same', activation='relu'),\n",
        "    layers.Conv2D(64, (5,5), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D(2),\n",
        "\n",
        "\n",
        "    # Block 3\n",
        "    layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
        "    layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D(2),\n",
        "\n",
        "    # Block 4\n",
        "    layers.Conv2D(256, (3,3), padding='same', activation='relu'),\n",
        "    layers.Conv2D(256, (3,3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D(2),\n",
        "\n",
        "    # Flatten Head\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(6, activation='softmax'),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cKAMrovToBK"
      },
      "source": [
        "# Testing CNN model with Flattening\n",
        "\n",
        "https://www.kaggle.com/code/ahmadjaved097/multiclass-image-classification-using-cnn\n",
        "\n",
        "Flatten is used in CNNs to transition convolutional feature maps to fully connected layers. Flatten simpler unrolls all the values in the feature maps into a single vector. This can result in a large number of parameters. 5+ million in this case.\n",
        "\n",
        "Best Val Accuracy: 0.6549\n",
        "\n",
        "Best Val Loss: 1.2699 (Epoch 12 — model checkpoint saved)\n",
        "\n",
        "Final Train Accuracy: 0.8668\n",
        "\n",
        "Final Train Loss: 0.6543\n",
        "\n",
        "Final Val Accuracy: 0.6549\n",
        "\n",
        "Final Val Loss: 1.5469\n",
        "\n",
        "Test Accuracy: 0.6554\n",
        "\n",
        "Test Loss: 1.4718"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVnsPh1dTPER"
      },
      "outputs": [],
      "source": [
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model_flatten.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "model_flatten.compile(\n",
        "    optimizer=Adam(learning_rate=1e-3),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_flatten.summary()\n",
        "\n",
        "history = model_flatten.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator_data,\n",
        "    epochs=30,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model_flatten.evaluate(X_test,\n",
        "    y_test,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P2-UQ9WUS1b"
      },
      "source": [
        "# Testing CNN with Global Average Pooling\n",
        "\n",
        "Using ChatGPT and Kaggle, I found that GAP or Global Average Pooling can significantly reduce the number of parameters. This method compresses each feature map into a single value by averaging its activations (outputs). This reduced our dimensionality from 5+ million to about 56K. This also allows the model to generalize better and train faster.\n",
        "https://www.kaggle.com/code/faressayah/cifar-10-images-classification-using-cnns-88\n",
        "https://www.kaggle.com/code/zlatan599/f1-0-97-garbage-classif-final-version-2\n",
        "\n",
        "The baseline run of this model with no dropout, data augmentation, or hyperparameter tuning was:\n",
        "\n",
        "* Time:\n",
        "* Val Acc:\n",
        "* Val Loss:\n",
        "* Train Acc:\n",
        "* Train Loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGP6Lg4EURjz"
      },
      "outputs": [],
      "source": [
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "model_gap.compile(\n",
        "    optimizer=Adam(learning_rate=1e-3),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_gap.summary()\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model_gap.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history_gap = model_gap.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator_data,\n",
        "    epochs=30,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model_gap.evaluate(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=2\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN0P5SnJvXW6VAOUV2ZJOjw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}